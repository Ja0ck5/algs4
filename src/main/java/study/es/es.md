

## translog

写入ES的数据首先会被写入translog文件，该文件持久化到磁盘，保证服务器宕机的时候数据不会丢失，由于顺序写磁盘，速度也会很快。

同步写入：每次写入请求执行的时候，translog在fsync到磁盘之后，才会给客户端返回成功
异步写入：写入请求缓存在内存中，每经过固定时间之后才会fsync到磁盘，写入量很大，对于数据的完整性要求又不是非常严格的情况下，可以开启异步写入


## refresh

经过固定的时间，或者手动触发之后，将内存中的数据构建索引生成segment，写入文件系统缓冲区

## commit/flush

超过固定的时间，或者translog文件过大之后，触发flush操作：

```text
1. 内存的buffer被清空，相当于进行一次refresh

2. 文件系统缓冲区中所有segment刷写到磁盘

3. 将一个包含所有段列表的新的提交点写入磁盘

4. 启动或重新打开一个索引的过程中使用这个提交点来判断哪些segment隶属于当前分片

5. 删除旧的translog，开启新的translog
```

## merge

上面提到，每次refresh的时候，都会在文件系统缓冲区中生成一个segment，后续flush触发的时候持久化到磁盘。

所以，随着数据的写入，尤其是refresh的时间设置的很短的时候，磁盘中会生成越来越多的

## segment

1. segment数目太多会带来较大的麻烦。 每一个segment都会消耗文件句柄、内存和cpu运行周期。
2. 更重要的是，每个搜索请求都必须轮流检查每个segment，所以segment越多，搜索也就越慢。

## merge的过程大致描述如下：

```text
1. 磁盘上两个小segment：A和B，内存中又生成了一个小segment：C

2. A,B被读取到内存中，与内存中的C进行merge，生成了新的更大的segment：D

3. 触发commit操作，D被fsync到磁盘

4. 创建新的提交点，删除A和B，新增D

5. 删除磁盘中的A和B

```

### Segment的不可变性的好处

1. segment的读写不需要加锁

2. 常驻文件系统缓存（堆外内存）

3. 查询的filter缓存可以常驻内存（堆内存）


#### 删除

磁盘上的每个segment都有一个.del文件与它相关联。当发送删除请求时，该文档未被真正删除，而是在.del文件中标记为已删除。此文档可能仍然能被搜索到，但会从结果中过滤掉。

当segment合并时，在.del文件中标记为已删除的文档不会被包括在新的segment中，

也就是说merge的时候会真正删除被删除的文档。

#### 更新

创建新文档时，Elasticsearch将为该文档分配一个版本号。

对文档的每次更改都会产生一个新的版本号。

当执行更新时，旧版本在.del文件中被标记为已删除，并且新版本在新的segment中写入索引。

旧版本可能仍然与搜索查询匹配，但是从结果中将其过滤掉

#### 版本控制

通过添加版本号的乐观锁机制保证高并发的时候，数据更新不会出现线程安全的问题，避免数据更新被覆盖之类的异常出现。

使用内部版本号：删除或者更新数据的时候，携带_version参数，如果文档的最新版本不是这个版本号，那么操作会失败，这个版本号是ES内部自动生成的，每次操作之后都会递增一。



## 原始文档存储（行式存储）

![](./original-file.jpg)

### fdt文件
    
文档内容的物理存储文件，由多个chunk组成，Lucene索引文档时，先缓存文档，缓存大于16KB时，就会把文档压缩存储

![](./fdt.jpg)


### fdx 文档内容的位置索引，由多个block组成：

1. 1024个chunk归为一个block

2. block记录chunk的起始文档ID，以及chunk在fdt中的位置

![](./fdx.jpg)

### fnm文件 文档元数据信息，包括文档字段的名称、类型、数量等。

![](./fnm.jpg)
lucene对原始文件的存放是行式存储，并且为了提高空间利用率，

是多文档一起压缩，因此取文档时需要读入和解压额外文档，因此取文档过程非常依赖CPU以及随机IO

#### 压缩方式的设置

原始文档的存储对应_source字段，是默认开启的，会占用大量的磁盘空间，上面提到的chunk中的文档压缩，ES默认采用的是LZ4，

如果想要提高压缩率，可以将设置改成best_compression。


#### 特定字段的内容存储

查询的时候，如果想要获取原始字段，需要在_source中获取，因为所有的字段存储在一起，所以获取完整的文档内容与获取其中某个字段，在资源消耗上几乎相同，只是返回给客户端的时候，减少了一定量的网络IO。

ES提供了特定字段内容存储的设置，在设置mappings的时候可以开启，默认是false。如果你的文档内容很大，而其中某个字段的内容有需要经常获取，可以设置开启，将该字段的内容单独存储。

PUT my_index
```json
{
  "mappings": {
    "_doc": {
      "properties": {
        "title": {
          "type": "text",
          "store": true 
        }
      }
    }
  }
}
```

## 倒排索引

![](./reverse-index.jpg)

倒排索引中记录的信息主要有：

```text
1. 文档编号：segment内部文档编号从0开始，最大值为int最大值，文档写入之后会分配这样一个顺序号

2. 字典：字段内容经过分词、归一化、还原词根等操作之后，得到的所有单词

3. 单词出现位置：分词字段默认开启，提供对于短语查询的支持；对于非常常见的词，例如the，位置信息可能占用很大空间，短语查询需要读取的数据量很大，查询速度慢

4. 单词出现次数：单词在文档中出现的次数，作为评分的依据

5. 单词结束字符到开始字符的偏移量：记录在文档中开始与结束字符的偏移量，提供高亮使用，默认是禁用的

6. 规范因子：对字段长度进行规范化的因子，给予较短字段更多权重
```

```text
倒排索引的查找过程本质上是通过单词找对应的文档列表的过程，

因此倒排索引中字典的设计决定了倒排索引的查询速度，

字典主要包括前缀索引（.tip文件）和后缀索引（.tim）文件。

```

### 字典前缀索引（.tip文件）

FST(Finite State Transducer) 有限状态传感器
![](./fst.jpg)

Lucene采用的前缀索引数据结构为FST，它的优点有：
词查找复杂度为O(len(str))

1. 共享前缀、节省空间、内存占用率低，压缩率高，模糊查询支持好
2. 内存存放前缀索引，磁盘存放后缀词块
3. 缺点：结构复杂、输入要求有序、更新不易


### 字典后缀（.tim文件）

后缀词块主要保存了单词后缀，以及对应的文档列表的位置。

### 文档列表（.doc文件）

![](./doc.jpg)

lucene对文档列表存储进行了很好的压缩，来保证缓存友好：

```text

1. 差分压缩：每个ID只记录跟前面的ID的差值

2. 每256个ID放入一个block中

3. block的头信息存放block中每个ID占用的bit位数，因为经过上面的差分压缩之后，文档列表中的文档ID都变得不大，占用的bit位数变少

```

### ES的一个重要的查询场景是bool查询

类似于mysql中的and操作，需要将两个条件对应的文档列表进行合并。

为了加快文档列表的合并，lucene底层采用了跳表的数据结构，

合并过程中，优先遍历较短的链表，去较长的列表中进行查询

### 倒排索引的查询过程
    
![](./reverse-index-search.jpg)

```text

1. tip字典前缀: 内存加载tip文件，通过FST匹配前缀找到后缀词块位置

2. tim字典后缀: 根据词块位置，读取磁盘中tim文件中后缀块并找到后缀和相应的倒排表位置信息

3. doc文件: 根据倒排表位置去doc文件中加载倒排表

4. skiplist 合并: 借助跳表结构，对多个文档列表进行合并

```

## DocValues（正排索引&列式存储）

倒排索引保存的是词项到文档的映射

DocValues保存的是文档到词项的映射，也就是文档中有哪些词项


DocValues采用的数据结构是bitset，bitset对于稀疏数据的支持不好：

1. 对于稀疏的字段来说，绝大部分的空间都被0填充，浪费空间
2. 由于字段的值之间插入了0，可能本来连续的值被0间隔开来了，不利于数据的压缩
3. 空间被一堆0占用了，缓存中缓存的有效数据减少，查询效率也会降低


## 查询过程（query then fetch）

```text
1. 协调节点将请求发送给对应分片

2. 分片查询，返回from+size数量的文档对应的id以及每个id的得分

3. 汇总所有节点的结果，按照得分获取指定区间的文档id

4. 根据查询需求，像对应分片发送多个get请求，获取文档的信息

5. 返回给客户端
```

### get查询更快

默认根据id对文档进行路由，所以指定id的查询可以定位到文档所在的分片，只对某个分片进行查询即可。当然非get查询，只要写入和查询的时候指定routing，同样可以达到该效果。

主分片与副本分片

ES的分片有主备之分，但是对于查询来说，主备分片的地位完全相同，平等的接收查询请求。这里涉及到一个请求的负载均衡策略，6.0之前采用的是轮询的策略，但是这种策略存在不足，轮询方案只能保证查询数据量在主备分片是均衡的，但是不能保证查询压力在主备分片上是均衡的，可能出现慢查询都路由到了主分片上，导致主分片所在的机器压力过大，影响了整个集群对外提供服务的能力。

新版本中优化了该策略，采用了基于负载的请求路由，基于队列的耗费时间自动调节队列长度，负载高的节点的队列长度将减少，让其他节点分摊更多的压力，搜索和索引都将基于这种机制。

### get查询的实时性

ES数据写入之后，要经过一个refresh操作之后，才能够创建索引，进行查询。但是get查询很特殊，数据实时可查。

ES5.0之前translog可以提供实时的CRUD，get查询会首先检查translog中有没有最新的修改，然后再尝试去segment中对id进行查找。5.0之后，为了减少translog设计的负责性以便于再其他更重要的方面对translog进行优化，所以取消了translog的实时查询功能。

get查询的实时性，通过每次get查询的时候，如果发现该id还在内存中没有创建索引，那么首先会触发refresh操作，来让id可查。



Max number of nodes = Number of shards * (number of replicas +1)

换句话说，如果你计划用10个分片和2个分片副本，那么最大的节点数是30。


### 分析器(analyzer)

当索引一个文档时，它的全文域被分析成词条以用来创建倒排索引。

当进行分词字段的搜索的时候，同样需要将查询字符串通过相同的分析过程，以保证搜索的词条格式与索引中的词条格式一致。当查询一个不分词字段时，不会分析查询字符串，而是搜索指定的精确值。





https://segmentfault.com/a/1190000020022504



